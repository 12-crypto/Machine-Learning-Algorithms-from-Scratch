{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6cbb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19af23dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6660217",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array(boston.data)\n",
    "l = np.array(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86a8083f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "print(f.shape,l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86630373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 1)\n"
     ]
    }
   ],
   "source": [
    "l = np.reshape(l,(-1,1))\n",
    "print(l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "180d42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(d):\n",
    "    m = np.mean(d)\n",
    "    sd = np.std(d)\n",
    "    normalised_d = (d-m)/sd\n",
    "    return normalised_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60269bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = normalise(f)\n",
    "l = normalise(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93dbf64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_f = np.ones(shape=(f.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8b47bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.concatenate((f, bias_f), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d281005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    }
   ],
   "source": [
    "print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66e3977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, Y_train,Y_test = train_test_split(f,l,test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7aa38f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 14) (102, 14) (404, 1) (102, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape, Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d289a718",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5db23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_s = f.shape[0]\n",
    "n_f = f.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f845440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "091ee861",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[None,n_f])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1bea163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(14, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "W=tf.Variable(tf.random_normal(shape=(n_f,1)))\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d31307b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.matmul(X,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf20c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(y_pred-Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f17e0e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3dc67f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n",
      "Training loss is 16.6024 and testing loss in 17.9712\n",
      "-------\n",
      "Epoch 2\n",
      "\n",
      "Training loss is 36.3272 and testing loss in 35.6762\n",
      "-------\n",
      "Epoch 3\n",
      "\n",
      "Training loss is 82.5613 and testing loss in 87.0522\n",
      "-------\n",
      "Epoch 4\n",
      "\n",
      "Training loss is 190.1813 and testing loss in 190.2582\n",
      "-------\n",
      "Epoch 5\n",
      "\n",
      "Training loss is 440.2468 and testing loss in 456.9725\n",
      "-------\n",
      "Epoch 6\n",
      "\n",
      "Training loss is 1021.0341 and testing loss in 1033.4084\n",
      "-------\n",
      "Epoch 7\n",
      "\n",
      "Training loss is 2369.7766 and testing loss in 2440.0891\n",
      "-------\n",
      "Epoch 8\n",
      "\n",
      "Training loss is 5501.8203 and testing loss in 5600.2637\n",
      "-------\n",
      "Epoch 9\n",
      "\n",
      "Training loss is 12774.9736 and testing loss in 13104.0566\n",
      "-------\n",
      "Epoch 10\n",
      "\n",
      "Training loss is 29664.4824 and testing loss in 30273.7754\n",
      "-------\n",
      "Epoch 11\n",
      "\n",
      "Training loss is 68884.7969 and testing loss in 70537.7422\n",
      "-------\n",
      "Epoch 12\n",
      "\n",
      "Training loss is 159960.9688 and testing loss in 163434.6406\n",
      "-------\n",
      "Epoch 13\n",
      "\n",
      "Training loss is 371455.2188 and testing loss in 380079.5625\n",
      "-------\n",
      "Epoch 14\n",
      "\n",
      "Training loss is 862580.9375 and testing loss in 881756.1875\n",
      "-------\n",
      "Epoch 15\n",
      "\n",
      "Training loss is 2003057.1250 and testing loss in 2048884.8750\n",
      "-------\n",
      "Epoch 16\n",
      "\n",
      "Training loss is 4651436.5000 and testing loss in 4755877.0000\n",
      "-------\n",
      "Epoch 17\n",
      "\n",
      "Training loss is 10801422.0000 and testing loss in 11046965.0000\n",
      "-------\n",
      "Epoch 18\n",
      "\n",
      "Training loss is 25082728.0000 and testing loss in 25648332.0000\n",
      "-------\n",
      "Epoch 19\n",
      "\n",
      "Training loss is 58246328.0000 and testing loss in 59566736.0000\n",
      "-------\n",
      "Epoch 20\n",
      "\n",
      "Training loss is 135257760.0000 and testing loss in 138313360.0000\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #imp step\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        sess.run(opt, feed_dict ={\n",
    "            X: X_train,\n",
    "            Y: Y_train\n",
    "        })\n",
    "        \n",
    "        train_loss = sess.run(cost, feed_dict={\n",
    "            X: X_train,\n",
    "            Y: Y_train\n",
    "        })\n",
    "        \n",
    "        test_loss = sess.run(cost, feed_dict={\n",
    "            X : X_test,\n",
    "            Y : Y_test \n",
    "        })\n",
    "        print(\"Epoch\",format(epoch+1))\n",
    "        print(\"\\nTraining loss is {:.04f} and testing loss in {:0.04f}\".format(train_loss,test_loss))\n",
    "        print(\"-------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
